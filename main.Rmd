---
title: "Kaggle House Prices"
author: "Javier Guzmán Figueira Domínguez"
date: "04/03/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(tidy.opts = list(width.cutoff = 60), tidy = TRUE)
knitr::opts_knit$set(root.dir = "C:/Users/cento/Documents/MasterUIMP/Practicas/aprendizajeautomatico/kaggle_house_prices")
```

# Introducción

El objetivo de este documento es el realizar una predicción de precios de ventas de propiedades inmobiliarias, en base al [problema](https://www.kaggle.com/c/house-prices-advanced-regression-techniques) publicado en la plataforma Kaggle. Por consiguiente, el objetivo de minería de datos será: la construcción de un modelo inteligible que obtenga una estimación lo más precisa posible del atributo clase *"SalePrice"*, a partir del resto. El nombre de usuario empleado en la plataforma Kaggle es **CDAA17JGFigueira**.

## Carga de liberías y datos

Previante a realizar un análisis de los datos, se procede a cargar las liberías de R requeridas para su realización. Así mismo, se cargan los conjuntos de datos de entrenamiento y tests.

```{r}
required_packages <- c("ggplot2", "dplyr", "caret", "kernlab", "glmnet", "xgboost", "data.table", "Metrics", "cowplot", "caretEnsemble")
new_packages <- required_packages[!(required_packages %in% installed.packages()[, "Package"])]
if (length(new_packages)) install.packages(new_packages)

library(ggplot2)
library(dplyr)
library(caret)
library(kernlab)
library(glmnet)
library(xgboost)
library(data.table)
library(Metrics)
library(cowplot)
library(caretEnsemble)

SEED <- 12345
train <- read.csv("data/train.csv")
test <- read.csv("data/test.csv")
```

# Inspección de los datos

## Análisis preliminar

Como primer paso del proceso, se procede a realizar un análisis de los datos. Para ello, es necesario conocer las dimensiones del conjunto de entrenamiento.

```{r}
dim(train)
dim(test)
```

Se observa que el número de instancias del conjunto de entrenamiento contiene prácticamente el mismo número de instancias que el conjunto de test. Sin embargo, este último contiene una variable menos, que se corresponde con la ausencia de variable clase *SalePrice*.

Teniendo en cuenta que en el futuro se harán distintas modificaciones sobre los datos y éstas se deberían realizar teniendo en cuenta el conjunto total de los datos, se procede a juntar los dos conjuntos. Para ello, rellenamos con *NA* los valores ausentes del conjunto de test. Por consiguiente, cuando se realice una operación que tenga en cuenta la variable *SalePrice* (por ejemplo: la correlación entre una de las características y la variable clase), sólo se podrá realizar sobre el subconjunto de test.

Para tener actualizadas ambos subconjuntos, se defina la función *updatePartitions*. De esta forma, todas las operaciones que se apliquen al total de los datos, se verán reflejadas en ambas particiones.

```{r}
full.set <- data.frame(data.table::rbindlist(list(train, cbind(test, SalePrice = as.integer(NA))),
                                             use.names = F, fill = F))
dim(full.set)

updatePartitions <- function() {
    train.size <- nrow(train)
    full.set.size <- nrow(full.set)

    train <<- full.set[c(1:train.size),]
    test <<- full.set[c((train.size + 1):full.set.size),]
}
```

A continuacin, procedemos a examinar las variables del dataset y observamos que coinciden con las descritas por la [plataforma](https://www.kaggle.com/c/5407/download/data_description.txt).

```{r}
str(full.set)
```

Así mismo, observamos la información relevante del dataset para tener una idea de sus características. Se aprecia presencia de tanto características numéricas continuas, como ordinálisis y categóricas. También se aprecia una gran presencia de valores perdidos (*NA*) en bastantes características.

```{r}
summary(full.set)
```

Otra característica a destacar es la elevada diferencia entre los valores de la media (180921) y la mediana (163000) de la variable clase *SalePrice* ($17921 de diferencia). Esto puede apuntar a una desviación por la presencia de valores anómalos.

```{r}
par(mfrow = c(2, 2))

hist(train$SalePrice, main = "SalePrice", xlab = "")
hist(log10(train$SalePrice), main = "Log10(SalePrice)", xlab = "")

boxplot(train$SalePrice, main = "SalePrice")
boxplot(log10(train$SalePrice), main = "Log10(SalePrice)")

par(mfrow = c(1, 1))
```

Se ha podido comprobar la clara desviación de los datos y como la aplicación de logaritmos ayuda en su corrección. De esta forma, se aplicará esta modificación para eliminar esta asimetria (o sesgo) en las operaciones que utilicen esta variable.

## Análisis de valores perdidos

Dado que se ha advertido de una elevada presencia de valores perdidos, se procede a la obtener una información clara de los valores perdidos que contiene cada característica. Para ello se define la función *getLostValuesStats*, de esta forma se podrá comprobar recurrentemente, de una forma rápida, cuántos valores perdidos quedan por tratar.

```{r}
getLostValuesStats <- function() {
    lost.count <- colSums(sapply(select(full.set, - SalePrice), is.na))
    lost.count <- subset(lost.count, lost.count > 0)
    lost.percentage <- (lost.count / nrow(full.set)) * 100

    return(data.frame(lost.count, lost.percentage))
}

getLostValuesStats()
```

Ahora se procede a obtener una visual del estado del conjunto de datos, en cuanto lo que se refiere a la inclusión de este tipo de valores.

```{r}
lost.values.count <- full.set[, colSums(is.na(select(full.set, - SalePrice))) > 0]

is.lost.value <- as.data.frame(ifelse(is.na(lost.values.count), 0, 1))
is.lost.value <- is.lost.value[, order(colSums(is.lost.value))]

is.lost.value.grid <- expand.grid(list(x = 1:nrow(is.lost.value), y = colnames(is.lost.value)))
is.lost.value.grid$m <- as.vector(as.matrix(is.lost.value))
is.lost.value.grid <- data.frame(x = unlist(is.lost.value.grid$x), y = unlist(is.lost.value.grid$y), m = unlist(is.lost.value.grid$m))

ggplot2::ggplot(is.lost.value.grid) +
    geom_tile(aes(x = x, y = y, fill = factor(m))) +
    scale_fill_manual(values = c("white", "black"), name = "Perdido:\n  0: Si\n  1: No") +
    theme_light() +
    ylab("") +
    xlab("") +
    ggtitle("Valores perdidos en el conjunto total de datos")
```

## Tratamiento de los valores perdidos

Dada la heterogeneidad de los valores faltantes, se procederá a un análisis muy pormenorizado. En primer lugar, se tratarán las características numéricas con valores faltantes más representativos y luego se analizarán las variables categóricas.

En primer lugar, se procede a examinar la distribución de las variables numéricas, que contengan valores perdidos, con respecto a la variable *Log(SalePrice)*. Se puede observar que, además de la presencia de valores perdidos, hay algunas variables que contienen un elevado número de entradas con valor 0 (por ejemplo: *MasVnrArea*).

```{r}
lost.values.features <- rownames(getLostValuesStats())
numeric.features <- names(train)[which(sapply(train, is.numeric))]
lost.values.features.numeric <- dplyr::intersect(numeric.features, lost.values.features)

plots <- lapply(lost.values.features.numeric, function(feature) {
    ggplot(data = train, aes(x = train[, feature], y = log(train$SalePrice))) +
          geom_point() +
          geom_smooth(method = "lm") +
          xlab(label = feature) +
          ylab(label = "Price")
})

cowplot::plot_grid(plotlist = plots, ncol = 3)
```

### GarageYrBlt

Se aprecia que *GarageYrBlt* (año de construcción del garage) es una propidad que, lógicamente, está muy relacionada con *YearBuilt* (año de construcción). En general, se puede decir que *GarageYrBlt* tiende a ser igual a *YearBuilt*. Por consiguiente, en los valores perdidos de GarageYrBlt, se procede a asígnar el correspondiente valor de YearBuilt.

Así mismo, en la gráfica se observa la existencia de una inconsistencia, dado que una de la instancias toma valor 2207, cuando no es posible que contenga dicho año. Se sobreentiende que el valor que debería contener es 2007.

```{r}
ggplot(data = full.set, aes(x = GarageYrBlt, y = YearBuilt)) +
          geom_point() +
          geom_smooth(method = "lm")

full.set$GarageYrBlt[full.set$GarageYrBlt == 2207] <- 2007
selected <- is.na(full.set$GarageYrBlt)
full.set$GarageYrBlt[selected] <- full.set$YearBuilt[selected]

updatePartitions() # Se actualizan los subconjuntos de entrenamiento y test
```

### LotFrontage

Por lógica, se puede decir que el área de la propiedad (*LotArea*) guarda relación con la longitud de la fachada (*LotFrontage*). Para confirmarlo, comprobamos la correlación entre ellas:

```{r}
cor(full.set$LotFrontage, full.set$LotArea, use = "complete.obs")
cor(log(full.set$LotFrontage), log(full.set$LotArea), use = "complete.obs")
```

Y visualizamos su relación:

```{r}
plotLotRelation <- ggplot(data = full.set, aes(x = LotArea, y = LotFrontage)) +
    geom_point() +
    geom_smooth(method = "lm")

plotLogLotRelation <- ggplot(data = full.set, aes(x = log(LotArea), y = log(LotFrontage))) +
          geom_point() +
          geom_smooth(method = "lm")

cowplot::plot_grid(plotLotRelation, plotLogLotRelation, ncol = 2)
```

Se puede confirmar que existe una importante correlación entre *LotFrontage* y *LotArea*. Dado que estas dos propiedades están relacionadas, seguramente una de ellas sea desechada en el proceso de selección de variables. Independientemente de ello, en este paso sustituiremos los valores de *LotFrontage*, por la mediana de los valores existentes.

```{r}
selected <- is.na(full.set$LotFrontage)
full.set$LotFrontage[selected] <- mean(full.set$LotFrontage[!selected])

updatePartitions()
```

Finalmente, observamos la correlaciones después de realizar las modificaciones y apreciamos como se han modificado pero siguen conservando la misma tendencia.

```{r}
cor(full.set$LotFrontage, full.set$LotArea, use = "complete.obs")
cor(log(full.set$LotFrontage), log(full.set$LotArea), use = "complete.obs")
```

Visualmente se aprecia que la correlación continúa siendo similar, después de tratar los valores perdidos en *LotFrontage*.

```{r}
ggplot(data = full.set, aes(x = log(LotArea), y = log(LotFrontage))) +
          geom_point() +
          geom_smooth(method = "lm")
```

### MasVnrArea

En esta característica (área de chapa de mampostería), existen una gran cantidad de entradas con valor 0. Esto, seguramente, se deba a la carencia de chapado en la vivienda. Para confirmarlo, visualizamos el cruce entre esta variable y el precio de venta (*SalePrice*), clasificando las intancias según el tipo de chapado de mampostería que tiene la vivienda.

```{r}
ggplot2::qplot(data = train, x = log(MasVnrArea), y = log(SalePrice), col = MasVnrType)
```

También observamos que en ambas variables los valores perdidos (8) forman parte, prácticamente, de los mismos ejemplos:

```{r}
full.set$Id[is.na(full.set$MasVnrArea)]
full.set$Id[is.na(full.set$MasVnrType)]
```

Se elimina la caraterística *MasVnrArea*, ya que las entradas con valor 0, por ser del tipo "None", hacen que la información desprendida de la variable esté deformada.

```{r}
full.set <- dplyr::select(full.set, - MasVnrArea)

updatePartitions()
```

Ahora se deben tratar los valores perdidos de *MasVnrType*. Para ello, observamos *MasVnrType* en relación a *SalePrice* para entender su distribución.

```{r}
qplot(data = train, x = MasVnrType, y = log10(SalePrice), geom = c("boxplot"), fill = MasVnrType)
```

Asignamos a los valores perdidos el tipo *BrkFace*, por mayor proximidad de sus medias. Aunque también se les podría asignar el tipo "Stone".

```{r}
full.set$MasVnrType[is.na(full.set$MasVnrType)] <- "BrkFace"

updatePartitions()
```

Finalmente, observamos la distribución resultante en las categorías de *MasVnrType* en relación a *SalePrice*.

```{r}
qplot(data = train, x = train$MasVnrType, y = log10(train$SalePrice), geom = c("boxplot"), fill = train$MasVnrType)
```

### Tratamiento de variables categóricas

Las siguientes caraterísticas con valores perdidos se corresponden con aquellas que contienen entradas en las que hay una ausencia de la propiedad a la que representan. Por ejemplo, la propiedad *PoolQC* representa la calidad de la piscina. Pero es obvio que en aquellas propiedades en las haya una ausencia de piscina, será inviable representar su calidad. Por consiguiente, se le asignarán el tipo "None" a aquellos valores ausentes (*<NA>*). Las caracteríasticas que contienen este tipo de valores perdidos son:  *PoolQC*,   *MiscFeature*, *Alley*,  *Fence*, *FireplaceQu*, *GarageCond*, *GarageFinish*, *GarageQual*, *GarageType*, *BsmtCond*, *BsmtExposure*, *BsmtFinType1*, *BsmtFinType2* y *BsmtQual*.

```{r}
categorical.features <- c(
  "PoolQC",
  "MiscFeature",
  "Alley",
  "Fence",
  "FireplaceQu",
  "GarageCond",
  "GarageFinish",
  "GarageQual",
  "GarageType",
  "BsmtCond",
  "BsmtExposure",
  "BsmtFinType1",
  "BsmtFinType2",
  "BsmtQual"
  )

for (feature in categorical.features) {
    if (is.factor(full.set[, feature])) {
        full.set[, feature] <- as.character(full.set[, feature])
        full.set[, feature][which(is.na(full.set[, feature]))] <- "None"
        full.set[, feature] <- factor(full.set[, feature])
    }
}

updatePartitions()
```

### Electrical

Esta característica presenta solamente un valor perdido. Dada la mínima influencia que puede tener, se le asigna la categoría mayoritaria.

```{r}
full.set$Electrical[is.na(full.set$Electrical)] <- as.character(sort(full.set$Electrical, decreasing = TRUE)[1])

updatePartitions()
```

### Corrección de valores perdidos en el conjunto de test

Se examinan los valores perdidos que restan el dataset y se aprecia que aún existen algunos datos sin tratar. Aunque estas entradas pertenecen al conjunto de test, se proceden a procesar de la misma forma que se hizo en el conjunto de entrenamiento.

```{r}
getLostValuesStats()
```

Por una parte, se procesan las características de tipo numérico, asignando la mediana a los valores faltantes.

```{r}
lost.test.numeric.features <- c("BsmtFinSF1", "BsmtFinSF2", "BsmtUnfSF", "TotalBsmtSF", "BsmtFullBath", "BsmtHalfBath", "GarageCars", "GarageArea")

for (feature in lost.test.numeric.features) {
    full.set[, feature][is.na(full.set[, feature])] <- median(full.set[, feature][!is.na(full.set[, feature])])
}

updatePartitions()
```

En cuanto a las variables de tipo nominal, se les asigna la moda de sus valores.

```{r}
lost.test.categorical.features <- c("Exterior1st", "Exterior2nd", "Functional", "KitchenQual", "MSZoning", "SaleType", "Utilities")

for (feature in lost.test.categorical.features) {
    full.set[, feature][is.na(full.set[, feature])] <- as.character(sort(full.set[, feature], decreasing = T)[1])
}

updatePartitions()
```

Antes de continuar, comprobamos que no hay valores perdidos en ninguno de los dos conjuntos.

```{r}
getLostValuesStats()
```

# Transformación de los datos

En esta sección se procederá a aplicar determinados procesos sobre los datos, tales como: eliminación de variables superfluas, generación de variables, eliminación de intancias, escalado de los datos... de forma que se obtenga una conjunto de datos resultate óptimo para la creación del modelo.

En primer lugar, se procede a eliminar la propiedad *Id* de los conjuntos de entrenamiento y test, debido a su irrelevancia.

```{r}
train.transformed <- dplyr::select(train, - Id)
test.transformed <- dplyr::select(test, - Id)
```

## Tratamiento de outliers

En la fase de análisis de los datos se ha observado como la propiedad *GrLivArea* (area habitable de la vivienda), contiene algunas instancias que se podrían etiquetar como valores anómalos.

```{r}
plot.with.outliers <- ggplot(train.transformed, aes(y = SalePrice, x = GrLivArea)) +
    ggtitle("With Outliers") + geom_point()

plot.with.outliers.log <- ggplot(train.transformed, aes(y = log(SalePrice), x = log(GrLivArea))) +
    ggtitle("With Outliers (Log())") + geom_point()

cowplot::plot_grid(plot.with.outliers, plot.with.outliers.log, ncol = 2)
```

Se puede aprecicar como hay algunas intancias con valores muy alejados de la distribución. Incluso aplicando logaritmos, toman valores alejados de la distribución. Más adelante se comprobará como esta variable tiene una gran importancia en el model. Para evitar desviaciones, se procede a asignarles la media.

```{r}
GrLivArea.mean <- mean(train.transformed$GrLivArea) %>% as.numeric
train.transformed[train.transformed$GrLivArea > 4000,]$GrLivArea <- GrLivArea.mean
ggplot(train.transformed, aes(y = SalePrice, x = GrLivArea)) + ggtitle("Without Outliers") + geom_point()
```

Se procede a volver a unir ambos subconjuntos, para aplicar conjuntamente las siguientes transformaciones.

```{r}
full.set.transformed <- data.frame(data.table::rbindlist(list(train.transformed, test.transformed), use.names = F, fill = F))
```

### Ingeniería de caraterísticas

En este apartado, se procede a la eliminación y generacìón de características del dataset. Tal y como se ha comentado en el *"Análisis de valores perdidos"*, la característica *LotFrontage* es bastante redundante respecto a la propiedad *LotArea*. Y se ha "deformado" la correlación entre ambas al realizar el tratamiento de valores perdidos. Debido a esto, se procede a eliminar la característica.

Así mismo, se generan las siguientes características, que intuitivamente y tras sucesivas generaciones de modelos ayudan a la generalización del mismo:

- **TotalSF**: superficie de la vivienda, en pies cuadrados. Se genera utilizando las características que referencian la superficie del sótano (*TotalBsmtSF*), primer piso (*X1stFlrSF*) y segundo piso (*X2ndFlrSF*).
- **Age**: edad efectiva de la vivienda. Se genera sustayendo el año de remodelación de la vivienda (*YearRemodAdd*) al año de venta de la misma (*YrSold*).
- **TotalProch**: area total de porche, en pies cuatrados. Se genera utlizando las varariable que contienene información referente a las superficise de distintos tipos de porches (*EnclosedPorch*, *ScreenPorch* y *X3SsnPorch*).

```{r}
full.set.transformed <- dplyr::select(full.set.transformed, - LotFrontage)

full.set.transformed$TotalSF = full.set.transformed$TotalBsmtSF + full.set.transformed$X1stFlrSF + full.set.transformed$X2ndFlrSF

full.set.transformed$Age <- full.set.transformed$YrSold - full.set.transformed$YearRemodAdd

full.set.transformed$TotalProch <- full.set.transformed$EnclosedPorch + full.set.transformed$ScreenPorch + full.set.transformed$X3SsnPorch
```

### Regularización de las variables continuas

Tal y como se ha mostrado en al análisis preliminar, la variable *SalePrice* contiene una distribución asimétrica. Por consiguiente, para evitar el efecto que los valores extremos puedan causar, se procede a aplicar logaritmos a los valores de la distribución.

```{r}
full.set.transformed$SalePrice <- log(full.set.transformed$SalePrice)
```

Así mismo, se procede a mostrar diagramas de densidad de cada una de las características que contienen datos númericos. De esta forma, se podrán observar la tendencias de cada una de las distribuciones.

```{r}
continuous.features <- c(
  "LotArea", ## Lot size in square feet
  "BsmtFinSF1", ## Type 1 finished square feet    
  "BsmtFinSF2", ## Type 2 finished square feet
  "BsmtUnfSF", ## Unfinished square feet of basement area
  "TotalBsmtSF", ## Total square feet of basement area
  "X1stFlrSF", ## First Floor square feet
  "X2ndFlrSF", ## Second floor square feet
  "LowQualFinSF", ## Low quality finished square feet (all floors)
  "GrLivArea", ## Above grade (ground) living area square feet
  "GarageArea", ## Size of garage in square feet
  "WoodDeckSF", ## Wood deck area in square feet
  "OpenPorchSF", ## Open porch area in square feet  
  "EnclosedPorch", ## Enclosed porch area in square feet 
  "X3SsnPorch", ## Three season porch area in square feet 
  "ScreenPorch", ## Screen porch area in square feet
  "PoolArea" ## Pool area in square feet
)

plots <- lapply(continuous.features, function(feature) {
    if (is.numeric(full.set.transformed[, feature])) {
        ggplot2::ggplot(data = full.set.transformed,
        aes(x = full.set.transformed[, feature])) +
                      geom_density() +
                      xlab(feature)
    }
})

cowplot::plot_grid(plotlist = plots, ncol = 3)
```

Se aprecia una clara desviación en las distribuciones. Por consiguiente, aplicamos logaritmos a las caraterísticas de forma que en muchos casos obtenemos unas distribuciones más uniformes. Nótese que además se suma 1 a los datos, con el fin de evitar la operación *log(0)*.

```{r}
full.set.transformed[, continuous.features] <- log(1 + full.set.transformed[, continuous.features])

plots <- lapply(continuous.features, function(feature) {
    if (is.numeric(full.set.transformed[, feature])) {
        ggplot2::ggplot(data = full.set.transformed, aes(x = full.set.transformed[, feature])) +
                      geom_density() +
                      xlab(feature)
    }
})

cowplot::plot_grid(plotlist = plots, ncol = 3)
```

### Otras transformaciones

Con el fin de normalizar más los datos, se procede a aplicar un centrado y escalado de los conjunto de datos (extrayendo la variable clase).

```{r}
set.seed(SEED)
full.set.preProcessed <- caret::preProcess(select(full.set.transformed, - SalePrice), method = c("center", "scale"))
full.set.transformed <- predict(full.set.preProcessed, full.set.transformed)
```

Algunos tipos de métodos analíticos que tienen problemas al tratar variables categóricas. Por lo tanto, se procede a la conversión de dicho tipo de variables a numéricas. Para ello, se asigna a cada categoría un entero, generado de forma incremental en cada característica.

```{r}
for (i in 1:ncol(full.set.transformed)) {
    if (is.factor(full.set.transformed[, i])) {
        levels(full.set.transformed[, i]) <- c(1:length(levels(full.set.transformed[, i])))
        full.set.transformed[, i] <- as.numeric(full.set.transformed[, i])
    }
}
```

Así mismo, se ha observado que hay variables con una varianza muy cercana a 0. Aunque se utilizarán árboles de decisión para el modelado, este tipo de características suelen ser problemáticas y pueden hacer "quebrar" el modelo o volverlo inestable. Por consiguiente, se procede a indentificar dichas variables y eliminarlas.

```{r}
near.zero.features.index <- caret::nearZeroVar(full.set.transformed)
full.set.transformed <- full.set.transformed[, - near.zero.features.index]
```

# Entrenamiento del modelo

En primer lugar, se procede a volver a obtener los subconjuntos de entrenamiento y de test.

```{r}
train.processed <- full.set.transformed[1:nrow(train.transformed),]
test.processed <- full.set.transformed[(nrow(train.transformed) + 1):nrow(full.set.transformed),]
test.processed <- dplyr::select(test.processed, - SalePrice)
```

## Análisis exploratorio

De forma exploratoria, se procede a relizar una sencilla regresión linear y analizar la uniformación desprendida de su resultado. De esta forma obtenemos información sobre si nuestro conjunto de datos puede producir un buen modelo. Así, observando la primera gráfica se aprecia como los valores residuales se mantienen en torno a 0, especialmente en la zona de concentración de más instancias.

```{r}
exploratory.lm = lm(SalePrice ~ ., data = train.processed)

par(mfrow = c(2, 2))
plot(exploratory.lm)
par(mfrow = c(1, 1))
```

También puede ser interesante concer cuales son las características con más impacto en la generación del modelo. A continuación, se muestra un ranking de las quince características más salientables. De forma destacada, la más ìmporante es *OverallQual*, dato que nos será relevante más adelante.

```{r}
importance <- caret::varImp(exploratory.lm)
importance.sort <- sort(importance$Overall, decreasing = TRUE, index.return = TRUE)

data.frame("Feature" = rownames(importance)[importance.sort$ix], "Overall" = importance[importance.sort$ix,])[1:15,]
```

## Entrenamiento parcial

Dado que nuestro conjunto de test no contiene información de la variable clase *SalePrice*, no se puede realizar una validación clásica del modelo. Es decir, se podría comparar el *RMSE* obtenido en la plataforma Kaggle y compraralo con el respectivo del conjunto de entrenamiento. Sin embargo, perderíamos mucha información en el proceso y no sería demasiado extensible.

Por lo tanto, se realiza una partición del conjunto de entrenamiento de forma que generemos dos nuevos subconjutos. Es decir, un nuevo subconjunto de entrenamiento (70% de las intancias del conjunto de entrenamiento original) y otro subconjunto de validación (formado por el 30% de intancias restantes).

```{r}
set.seed(SEED)
train.processed.partition.index <- createDataPartition(train.processed$SalePrice, p = 0.7, list = FALSE)
train.processed.partition.train <- train.processed[train.processed.partition.index,]
train.processed.partition.validation <- train.processed[-train.processed.partition.index,]
```

Ahora se procede al entrenamiento del modelo. Se ha elegido un método de *Gradient boosting*, basado en árboles de decisión.

```{r}
set.seed(SEED)
garbage <- capture.output(
    model.partial <- caret::train(SalePrice ~ .,
      data = train.processed.partition.train,
      method = 'gbm',
      trControl = caret::trainControl(
      method = 'repeatedcv',
      number = 10,
      repeats = 1
      ))
)

model.partial
```

### Validación del modelo

Para la validación del modelo, se crea la función *predictAndEvaluate*, de forma que se genere la respectiva predicción y se genere una gráfica comparativa entre los valores predichos y la respectiva *RSME*.

```{r}
predictAndEvaluate <- function(model, validation.set) {
    validation.prediction <- stats::predict(model, dplyr::select(validation.set, - SalePrice))

    print(ggplot2::qplot(x = validation.prediction, y = validation.set$SalePrice,
               geom = c("point", "smooth"), method = "lm",
               xlab = "Predicted", ylab = "Real"))

    rmse(validation.set$SalePrice, validation.prediction)
}
```

Se procede a realizar la predicción del subconjunto de validación.

```{r}
predictAndEvaluate(model.partial, train.processed.partition.validation)
```

## Mejorando el modelo

Aunque no se han obtenido unos malos resultados, se quiere mejorar el entrenamiento del modelo. Para ello se ha creado al función *ensembleTrain*. Dicha función utiliza métodos del paquete *caretEnsemble*, de forma que permite combinar distintos modelos de *caret*. De esta forma, combinamos el *gbm* con otro tipo de árbol de decisión, un *xgbTree* o *eXtreme Gradient Boosting*. Así mismo, utlizamos la variable más relevante del dataset (*OverallQual*) para realizar un muestreo con *bootstrap*. Finalmente, juntamos los resultados basándonos en la métrica *RMSE*.

```{r}
ensembleTrain <- function(train.set) {
    set.seed(SEED)

    trControl <- trainControl(
        method = "cv",
        number = 7,
        savePredictions = "final",
        index = createResample(train.set$OverallQual, 7),
        allowParallel = TRUE
    )

    garbage <- capture.output(
        modelList <- caretList(
                      SalePrice ~ .,
                      data = train.set,
                      trControl = trControl,
                      metric = "RMSE",
                      tuneList = list(
        gbm = caretModelSpec(
                 method = "gbm", tuneGrid = expand.grid(n.trees = 700, interaction.depth = 5,
                 shrinkage = 0.05, n.minobsinnode = 10)),
        xgbTree = caretModelSpec(
                    method = "xgbTree", tuneGrid = expand.grid(nrounds = 2500, max_depth = 6, min_child_weight = 1.41,
                        eta = 0.01, gamma = 0.0468, subsample = 0.769, colsample_bytree = 0.283))
        ))
    )

    greedy_ensemble <- caretEnsemble(modelList, metric = "RMSE", trControl = trainControl(number = 25))

    return(greedy_ensemble)
}
```

Se puede observar que tanto en el conjunto de entrenamiento como en el de validación, los valores han mejorado. Así mismo, la predicción parece correcta en la gráfica.

```{r}
model.ensemble <- ensembleTrain(train.processed.partition.train)
model.ensemble
predictAndEvaluate(model.ensemble, train.processed.partition.validation)
```

# Entrenamiento y predicción

Finalmente, se procede al entrenamiento de la totalidad del conjunto de entrenamiento y a su predicción. El valor de *RMSE* obtenido en la plataforma Kaggle es de 0.12332, por un 0.1257321 obtenido en el conjunto de entrenamiento. Ámbos son unos valores muy silimares, lo que nos confirma la ausencia de bias y varianza en el modelo contruido.

```{r}
model.full <- ensembleTrain(train.processed)
model.full

predictions <- predict(model.full, newdata = test.processed)
prediction.table <- data.frame(Id = test$Id, SalePrice = exp(predictions))
write.csv(prediction.table, "prediction.csv", row.names = FALSE)
```

# Referencias

A continuación se detallan los *kernels* de Kaggle utlizados tanto como inspiración como fuente de fragmentos de código:

- https://www.kaggle.com/wangyizhou30/svm-more5/code
- https://www.kaggle.com/philip198/starting-out-with-r-house-prices-prediction/code
- https://www.kaggle.com/bwboerman/r-data-table-glmnet-xgboost-with-caret/notebook
- https://www.kaggle.com/mariopasquato/support-vector-regression/code
- https://www.kaggle.com/dataygun/a-story-of-just-everything
- https://www.kaggle.com/notaapple/detailed-exploratory-data-analysis-using-r
- https://www.kaggle.com/jimthompson/regularized-linear-models-in-r